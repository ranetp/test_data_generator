{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "from typing import List\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "\n",
    "while decrement:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt / 10)\n",
    "        decrement = True\n",
    "\n",
    "csv.field_size_limit(maxInt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random HTML generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_html_to_data(doc: str):\n",
    "    tags = ['p', 'div', 'html', 'body', 'span']\n",
    "    \n",
    "    tag = random.choice(tags)\n",
    "    opening = f'<{tag}>'\n",
    "    closing = f'</{tag}>'\n",
    "    \n",
    "    split_doc = doc.split(' ')\n",
    "    doc_words = len(split_doc)\n",
    "    start = random.randrange(0, doc_words)\n",
    "    end = random.randrange(start + 2, doc_words + 2)\n",
    "    split_doc.insert(start, opening)\n",
    "    split_doc.insert(end, closing)\n",
    "\n",
    "    new_doc = ' '.join(split_doc)\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path: Path):\n",
    "    print(path.exists(), path.is_dir(), path.is_file())\n",
    "    if path.exists() and path.is_file():\n",
    "        docs = []\n",
    "        with path.open() as f:\n",
    "            spamreader = csv.reader(f, delimiter=' ', quotechar='\"')\n",
    "            for row in spamreader:\n",
    "                html_doc = add_random_html_to_data(', '.join(row))\n",
    "                docs.append(html_doc)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = Path('test_et.csv')\n",
    "ru = Path('test_ru.csv')\n",
    "en = Path('test_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False True\n",
      "True False True\n",
      "True False True\n"
     ]
    }
   ],
   "source": [
    "est_docs = read_file(et)\n",
    "ru_docs = read_file(ru)\n",
    "en_docs = read_file(en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add HTML pages to the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html_page(path: Path):\n",
    "    if path.exists() and path.is_file():\n",
    "        with path.open() as f:\n",
    "            data = f.read()\n",
    "        return data\n",
    "    else:\n",
    "        raise Exception(f'Path exists: {path.exists()}, path is a file: {path.is_file()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_pages = []\n",
    "html_pages.append(read_html_page(Path('html/audio.htm')))\n",
    "html_pages.append(read_html_page(Path('html/canvas.htm')))\n",
    "html_pages.append(read_html_page(Path('html/google.htm')))\n",
    "html_pages.append(read_html_page(Path('html/examples.htm')))\n",
    "html_pages.append(read_html_page(Path('html/plugins.htm')))\n",
    "html_pages.append(read_html_page(Path('html/yt.htm')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_docs_and_key(docs: List[str], other_docs: List[str], key: str):\n",
    "    docs += other_docs\n",
    "    random.shuffle(docs)\n",
    "    new_docs = []\n",
    "    for doc in docs:\n",
    "        split_key = key.split('.')\n",
    "        split_key.reverse()\n",
    "        for sk in split_key:\n",
    "            doc = {sk: doc}\n",
    "        new_docs.append(doc)\n",
    "    return new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyed_et_docs = add_docs_and_key(est_docs, html_pages, 'est.mlp.text')\n",
    "# keyed_ru_docs = add_docs_and_key(ru_docs, html_pages, 'ru.text.mlp.text')\n",
    "# keyed_en_docs = add_docs_and_key(en_docs, html_pages, 'en-text.mlp.lemmas.text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_docs = add_docs_and_key(est_docs + ru_docs + en_docs, html_pages, 'foo.bar.text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### est.mlp.text | ru.text.mlp.text | en.text.mlp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_to_jl(docs1, docs2):\n",
    "    result = []\n",
    "    for doc1, doc2 in zip(docs1, docs2):\n",
    "        doc1.update(doc2)\n",
    "        result.append(doc1)\n",
    "    return result\n",
    "            \n",
    "        \n",
    "result = combine_to_jl(keyed_et_docs, keyed_ru_docs)\n",
    "result = combine_to_jl(result, keyed_en_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['est', 'ru', 'en-text']), 1013)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].keys(), len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(path: Path, docs: List[str]):\n",
    "    with path.open(mode='w', encoding='utf-8') as f:\n",
    "        for line in docs:\n",
    "            f.write(json.dumps(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = Path('result_small.jl')\n",
    "save(result_path, result[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['est', 'ru', 'en-text'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = Path('combined_small.jl')\n",
    "save(result_path, combined_docs[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
